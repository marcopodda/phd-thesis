\chapter{Conclusions and Future Works} % Main chapter title
\label{ch:conclusions}

We live in a world where the availability of rich, relational data increases at an astonishing rate. In this context, Deep Learning methodologies that learn from structured data offer an arguably unique combination of flexibility to handle heterogeneous data types, generality in terms of different learning paradigms covered, and powerful universal approximation capabilities. These characteristics match those of the life sciences domains, where data are generally relational, and learning problems arise from very complex and diverse processes. The main objective of this thesis has been to show this compatibility in a selection of real-world applications. Our study has concerned two somewhat different but equally relevant sub-domains of the life sciences: that of computational biology, where the focus has been on predictive learning of dynamical properties of biochemical pathways; and that of computational chemistry, where the focus has been on generative learning of molecules for \emph{de novo} drug design. In the following, we review our contributions in retrospect and highlight future research directions for each of them.
\vspace{1em}

The first contribution of this thesis has been an extensive and fair evaluation of Deep Graph Network models for graph classification tasks. Our work has been motivated by how the empirical comparison among models for graphs has been conducted in the literature over the last few years. We identified several flaws in the evaluation protocols, such as poor standardization across different works in terms of data splits used, ambiguous or under-specified selection of hyper-parameters, and unfair comparisons in terms of features used by the different models under evaluation. The major part of the study is a re-evaluation of 5 state-of-the-art models in the literature across 9 different datasets, of which 4 are related to the classification of chemical properties of graphs, and 5 concern predictive tasks on social networks. We devised a standardized evaluation framework consisting of an internal hold-out based model selection and an external 10-fold cross-validation for model assessment. Importantly, we took all the necessary precautions to design the framework as rigorously and fairly as possible: all models have been trained on the same stratified data splits and assigned a congruent amount of hyper-parameters to optimize during model selection. Moreover, we release our code and data splits to allow fellow researchers to replicate our experiments and use it for further comparison (see Appendix \ref{AppendixB}). One fundamental aspect of this work is the comparison against structure-agnostic baselines, which helps identify situations where the models do not fully exploit relational knowledge during the learning process. Our results differ from those reported in the literature and are more consistent with what would be expected from a robust assessment. Concerning the comparison with the baselines, we have shown that Deep Graph Networks do not perform better than structure-agnostic baselines in some cases. This result suggests care to not over-emphasize small performance improvements, which are more likely to be attributed to chance. Finally, we have shown how a fair comparison allows a reasoned analysis of specific properties of Deep Graph Networks. We have done so by demonstrating how using node degrees as features translates to a performance improvement across the social datasets; and which \glspl{dgn} seem to be most stable in performance responding to a change in hyper-parameters. In principle, our analysis can be extended indefinitely by further works: by applying the same fair evaluation to different datasets, such as those in the Stanford Large Network Dataset Collection \cite{leskovec2014snap}; by comparing more Deep Graph Networks variants; by enlarging the grids of hyper-parameters each model optimizes; and by refining the internal model selection phase using cross-validation for a less unbiased estimation. Most importantly, after our work on the subject has been published, we have started witnessing a collective effort to standardize model assessment for Deep Graph Networks by the research community \citep{hu2020ogb,morris2020tudatasets}.
\vspace{1em}

Our second contribution has been a novel application of Deep Graph Networks for graph classification to the problem of predicting the dynamical properties of biological pathways represented as graphs. Our focus has been on the property of robustness, which quantifies the stability of the associated dynamical system under perturbations of the initial conditions. Unlike traditional methods, which require to compute the robustness via expensive numerical simulations, we hypothesized that the structure of the graph representing the pathway correlates to its robustness and that this correlation could be exploited for predictive purposes. The potential implication of this assumption is that, to assess robustness or other dynamical properties, one is relieved from performing costly numerical simulations. Guided by this motivation, we developed a learning framework in which the structure of a biological pathway is given as input, and an indicator of whether the pathway is robust or not is predicted as output. The framework comprises a Deep Graph Network that processes the pathway structure and a downstream Multi-Layer Perceptron classifier, which takes care of the actual robustness prediction. We tested this framework on a dataset of real-world biological pathways taken from the BioModels database. The experimental results validate our initial assumption to a remarkable extent, paving the way for the use of learning methodologies to assess the dynamical properties of biochemical pathways. We have also shown that the pathway structure plays a major role to perform well in this task, since models that do not consider the pathway structure score not better than random. In subsequent works, it might be interesting to extend this approach further to the assessment of other dynamical properties of biochemical pathways, such as, for example, monotonicity, oscillatory, and bi-stability properties. Another fascinating research avenue concerns the development of novel Deep Generative Models of biochemical pathways. The potential of such development would be two-fold. Firstly, a generative model would endow researchers with an explanatory model of how pathway structure relates to the dynamical property. Secondly, it could allow the study of dynamical properties even in cases where not enough relevant pathways are available.
\vspace{1em}

The third contribution of our thesis has concerned the problem of graph generation. This problem is now being actively researched because of its connection to several domains such as network science or computational chemistry. Specifically, we developed a novel autoregressive model for unlabeled graph generation. Existing autoregressive approaches model graph generation in terms of sequences of nodes. We adopt a related but different formulation, which produces a graph by generating its sequence of edges ordered lexicographically. The autoregressive distribution is modeled by splitting the ordered edge sequence into two related sequences. The first is obtained from the edges' starting nodes, while the second is obtained from the ending nodes. To generate a graph, one firstly samples a sequence of starting nodes with an autoregressive \gls{rnn}. This initial sequence is ultimately completed into an ordered edge sequence by a second \gls{rnn} which predicts the end nodes sequence. We assess the performances of the proposed models on 6 different datasets, of which 4 are synthetic datasets of graphs with strong node/edge dependencies, and 2 are chemical datasets of molecules. The experimental evaluation has been conducted by taking into account quantitative (\ie how many useful graphs the model can produce) and qualitative (\ie how well the generated graphs resemble the training samples, both locally and globally) aspects. The results show that the model can approximate the desired graph distributions in all cases, performing on par with state-of-the-art approaches. The model also has limitations, in that it is not able (in its current form) to handle labeled generation, which is the next logical step to improve in subsequent works. Another interesting direction to take in the next future is to extend the model with attention mechanisms to integrate better the information provided by the first \gls{rnn} into the second. More generally, generative models of graphs still need to be researched further and in-depth. Among the many topics, one with arguably the highest impact on the field's advancement is the development of efficient permutation-invariant decoders.
\vspace{1em}

Lastly, we have presented an application of Deep Generative models of graphs in the context of molecular generation. Generating molecules is a critical phase of the drug discovery process, as it can potentially cut down the failures of the subsequent screening phases by selecting more suitable candidates. Approaches to the generation of molecules are based on two prominent model families. One approach is to linearize the molecular graphs in SMILES notation, learning a language model of strings in the SMILES language. The learned language model can be sampled to produce novel SMILES strings one character at a time. A different approach operates directly on the molecular graph, generating its structure either at once or sequentially by incrementally adding nodes to an existing graph. This approach is arguably considered more powerful, as it leverages a more expressive representation of the molecule. In comparison, the SMILES-based approach grants superior speed in the training and generation phases. However, it also generates chemically invalid and duplicate molecules at discouraging high rates. Our work has addressed these two limitations. Specifically, to solve the problems related to chemical validity, we have adopted a sequential generative approach based on chemical fragments. Chemical fragments are small compounds that can be combined to form more useful molecules. The proposed model generates molecules as sequences of fragments, rather than SMILES characters. This solution has two positive effects. Firstly, it reduces the length of the sequence to be generated, which implies faster computation and avoidance of long-term dependency problems. Secondly, it lowers the model's chances of making wrong predictions that can undermine the chemical validity of the graph being generated. To solve the problems regarding the generation of duplicate (\ie not unique) molecules, we have proposed a strategy termed Low-Frequency Masking. This strategy aims to encourage the model to generate molecules with fragments that appear less frequently in a dataset. We have tested our model on two major chemical benchmarks for molecule generation, evaluating it both quantitatively and qualitatively. The results show that our model dramatically improves upon SMILES-based models in the generation of valid and unique molecules, reaching a level of performances typical of the more expressive family of graph-based generative models. However, we also acknowledge that the model in its current form might have limited applicability to subsequent generative tasks in the drug discovery pipeline, such as molecular optimization. Overcoming this limitation constitutes an important research direction to pursue in subsequent works by devising more effective strategies to avoid the production of duplicates. A second improvement might be obtained by observing that the sequence of fragments is fully reversible: this means that one could try different strategies to construct the encoder, for example leveraging Bidirectional \glspl{lstm} \cite{schuster1997bidirectionallstm}. Lastly, a third improvement might be achieved by merging the fragment-based approach with graph-based methodologies. We believe this combination has a clear \quotes{best of both worlds} potential. On the one hand, it could exploit the advantages of fragment-based generation in terms of speed of training and sampling. On the other hand, it could leverage the expressiveness of a graph-based representation of the chemical fragments, similarly to other interesting approaches in the field \citep{jin2019multimodalmoltranslation,bradshaw2020barking}.
\vspace{1em}

In conclusion, we believe that the results presented in this thesis demonstrate the flexibility of Deep Learning to (\emph{a}) handle complex, variable-sized data structures, and (\emph{b}) leverage the expressiveness of these data to give important contributions in the two domains of application. On a more general level, we believe that this thesis gives a glimpse of the role that Deep Learning for structured data might play in the years to come. Some problems in the life sciences, like DNA analysis, require an astounding amount of computing power and memory to be tackled. Others, like the enumeration of all possible molecules, are simply impossible to solve naively. In these scenarios, one of the main roles of Deep Learning is likely that of a replacement or a complement for expensive numerical simulations or \emph{in vivo} experiments, with the ultimate promise of advancing the state of knowledge more efficiently. This process has already started in fields like computational chemistry, where using predictive or generative models can save researchers a tremendous amount of time (and money) to conduct their studies. The computational biology application presented in this thesis is another example of how the same goal can be achieved in a different life sciences domain. We expect many more cases where Deep Learning models break through the barriers of a difficult biological problem in the near future. In the route towards understanding the mechanisms underlying biological life, Deep Learning can help not to cover the entire distance but to take faster steps towards the destination.