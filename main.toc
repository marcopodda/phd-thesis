\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}
\contentsline {chapter}{Declaration of Authorship}{iii}{section*.1}
\contentsline {chapter}{Abstract}{vii}{section*.2}
\contentsline {chapter}{Acknowledgements}{ix}{section*.3}
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.6}
\contentsline {part}{I\hspace {1em}Preliminaries}{3}{part.7}
\contentsline {chapter}{\numberline {2}Machine Learning and Neural Networks}{5}{chapter.8}
\contentsline {section}{\numberline {2.1}Machine Learning}{5}{section.9}
\contentsline {section}{\numberline {2.2}Learning and Generalization}{6}{section.10}
\contentsline {subsection}{\numberline {2.2.1}Gradient-Based Optimization}{7}{subsection.11}
\contentsline {subsection}{\numberline {2.2.2}Overfitting}{8}{subsection.12}
\contentsline {subsection}{\numberline {2.2.3}Regularization}{8}{subsection.13}
\contentsline {section}{\numberline {2.3}Model Evaluation}{9}{section.15}
\contentsline {subsection}{\numberline {2.3.1}Model Selection}{9}{subsection.16}
\contentsline {section}{\numberline {2.4}Neural Networks}{10}{section.17}
\contentsline {subsection}{\numberline {2.4.1}Training}{13}{subsection.21}
\contentsline {subsection}{\numberline {2.4.2}Loss Functions}{13}{subsection.22}
\contentsline {paragraph}{Linear Output Layer}{14}{section*.23}
\contentsline {paragraph}{Logistic Output Layer}{14}{section*.24}
\contentsline {paragraph}{Softmax Output Layer}{15}{section*.25}
\contentsline {subsection}{\numberline {2.4.3}Regularization}{16}{subsection.26}
\contentsline {paragraph}{Penalized Loss Function}{16}{section*.27}
\contentsline {paragraph}{Early Stopping}{16}{section*.28}
\contentsline {paragraph}{Dropout}{16}{section*.29}
\contentsline {section}{\numberline {2.5}Auto-Encoders}{17}{section.30}
\contentsline {subsection}{\numberline {2.5.1}Regularized Auto-Encoders}{18}{subsection.32}
\contentsline {section}{\numberline {2.6}Deep Learning}{19}{section.34}
\contentsline {subsection}{\numberline {2.6.1}Convolutional Neural Networks}{20}{subsection.35}
\contentsline {section}{\numberline {2.7}Deep Generative Models}{21}{section.36}
\contentsline {subsection}{\numberline {2.7.1}Autoregressive Models}{22}{subsection.37}
\contentsline {subsection}{\numberline {2.7.2}Variational Auto-Encoders}{22}{subsection.38}
\contentsline {chapter}{\numberline {3}Deep Learning in Structured Domains}{25}{chapter.40}
\contentsline {section}{\numberline {3.1}Graphs}{25}{section.41}
\contentsline {paragraph}{Directed Graphs}{26}{section*.43}
\contentsline {paragraph}{Bipartite Graphs}{26}{section*.44}
\contentsline {paragraph}{Walks, Paths, and Cycles}{26}{section*.45}
\contentsline {paragraph}{Trees and Sequences}{27}{section*.46}
\contentsline {paragraph}{Subgraphs and Induced Subgraphs}{27}{section*.48}
\contentsline {subsection}{\numberline {3.1.1}Attributed Graphs}{28}{subsection.49}
\contentsline {subsection}{\numberline {3.1.2}Isomorphisms, Automorphisms, and Canonization}{28}{subsection.50}
\contentsline {subsection}{\numberline {3.1.3}Graphs as Matrices}{29}{subsection.52}
\contentsline {section}{\numberline {3.2}The Adaptive Processing of Structured Data}{29}{section.53}
\contentsline {section}{\numberline {3.3}Recurrent Neural Networks}{31}{section.54}
\contentsline {subsection}{\numberline {3.3.1}Training}{32}{subsection.55}
\contentsline {subsection}{\numberline {3.3.2}Gated Recurrent Neural Networks}{33}{subsection.58}
\contentsline {subsection}{\numberline {3.3.3}Recurrent Neural Networks as Autoregressive Models}{34}{subsection.59}
\contentsline {section}{\numberline {3.4}Recursive Neural Networks}{35}{section.61}
\contentsline {subsection}{\numberline {3.4.1}Training}{36}{subsection.62}
\contentsline {part}{II\hspace {1em}Deep Learning on Graphs with Applications to Computational Biology}{39}{part.64}
\contentsline {chapter}{\numberline {4}Deep Graph Networks}{41}{chapter.65}
\contentsline {section}{\numberline {4.1}Contextual Processing of Graph Information}{42}{section.66}
\contentsline {subsection}{\numberline {4.1.1}Recursive Approaches}{42}{subsection.68}
\contentsline {subsection}{\numberline {4.1.2}Feed-Forward Approaches}{43}{subsection.69}
\contentsline {subsection}{\numberline {4.1.3}Constructive Approaches}{44}{subsection.70}
\contentsline {section}{\numberline {4.2}Building Blocks of Deep Graph Networks}{44}{section.71}
\contentsline {subsection}{\numberline {4.2.1}Graph Convolutional Layers}{44}{subsection.72}
\contentsline {paragraph}{Handling Edges}{46}{section*.79}
\contentsline {paragraph}{Node Attention}{46}{section*.80}
\contentsline {paragraph}{Node Sampling}{47}{section*.82}
\contentsline {subsection}{\numberline {4.2.2}Readout Layers}{48}{subsection.84}
\contentsline {subsection}{\numberline {4.2.3}Graph Pooling Layers}{50}{subsection.87}
\contentsline {subsection}{\numberline {4.2.4}Regularization}{51}{subsection.89}
\contentsline {section}{\numberline {4.3}The Evaluation of Deep Graph Networks}{51}{section.92}
\contentsline {subsection}{\numberline {4.3.1}Datasets}{52}{subsection.93}
\contentsline {subsection}{\numberline {4.3.2}Architectures}{53}{subsection.95}
\contentsline {paragraph}{Graph Isomorphism Network}{53}{section*.96}
\contentsline {paragraph}{GraphSAGE}{54}{section*.97}
\contentsline {paragraph}{GraphSAGE + DiffPool}{54}{section*.98}
\contentsline {paragraph}{ECC}{54}{section*.99}
\contentsline {paragraph}{DGCNN}{55}{section*.100}
\contentsline {subsection}{\numberline {4.3.3}Baselines}{55}{subsection.101}
\contentsline {subsection}{\numberline {4.3.4}Experimental Setup}{56}{subsection.102}
\contentsline {paragraph}{Hyper-Parameters}{56}{section*.103}
\contentsline {paragraph}{Computational Considerations}{56}{section*.104}
\contentsline {subsection}{\numberline {4.3.5}Results}{57}{subsection.105}
\contentsline {paragraph}{The Importance of Baselines}{57}{section*.107}
\contentsline {paragraph}{The Effect of Node Degree}{58}{section*.109}
\contentsline {paragraph}{Comparison with Published Results}{59}{section*.111}
\contentsline {subsection}{\numberline {4.3.6}Conclusions}{59}{subsection.114}
\contentsline {chapter}{\numberline {5}Case Study: Prediction of Dynamical Properties of Biochemical Pathways using Deep Graph Networks}{61}{chapter.115}
\contentsline {section}{\numberline {5.1}Introduction and Motivation}{61}{section.116}
\contentsline {section}{\numberline {5.2}Background}{63}{section.118}
\contentsline {subsection}{\numberline {5.2.1}Pathway Petri Nets}{63}{subsection.119}
\contentsline {subsection}{\numberline {5.2.2}Concentration Robustness}{67}{subsection.123}
\contentsline {section}{\numberline {5.3}Methods}{68}{section.124}
\contentsline {subsection}{\numberline {5.3.1}Subgraphs Extraction}{68}{subsection.125}
\contentsline {subsection}{\numberline {5.3.2}Robustness Computation}{69}{subsection.128}
\contentsline {subsection}{\numberline {5.3.3}Data Preprocessing}{70}{subsection.130}
\contentsline {subsection}{\numberline {5.3.4}Subgraph Features}{71}{subsection.133}
\contentsline {section}{\numberline {5.4}Experiments}{71}{section.135}
\contentsline {part}{III\hspace {1em}Deep Generative Learning on Graphs with Applications to Computational Chemistry}{73}{part.136}
\contentsline {chapter}{\numberline {A}Frequently Asked Questions}{75}{appendix.137}
\contentsline {section}{\numberline {A.1}How do I change the colors of links?}{75}{section.138}
